# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ez6fz84q1E00qCpPl-LcThq9ZanJ42EF
"""

pip install opencv-python

"""
Traffic Sign Detection using OpenCV and a pre-trained model
This script captures video from a webcam, detects traffic signs, and draws bounding boxes around them.
"""

import cv2
import numpy as np
import time
from tensorflow.keras.models import load_model

# Define constants
TRAFFIC_SIGN_MODEL_PATH = 'traffic_sign_model.h5'  # Path to pre-trained model
CLASSES = ['Speed limit (20km/h)', 'Speed limit (30km/h)', 'Speed limit (50km/h)',
           'Speed limit (60km/h)', 'Speed limit (70km/h)', 'Speed limit (80km/h)',
           'End of speed limit (80km/h)', 'Speed limit (100km/h)', 'Speed limit (120km/h)',
           'No passing', 'No passing for vehicles over 3.5 metric tons',
           'Right-of-way at the next intersection', 'Priority road', 'Yield', 'Stop',
           'No vehicles', 'Vehicles over 3.5 metric tons prohibited', 'No entry',
           'General caution', 'Dangerous curve to the left', 'Dangerous curve to the right',
           'Double curve', 'Bumpy road', 'Slippery road', 'Road narrows on the right',
           'Road work', 'Traffic signals', 'Pedestrians', 'Children crossing',
           'Bicycles crossing', 'Beware of ice/snow', 'Wild animals crossing',
           'End of all speed and passing limits', 'Turn right ahead', 'Turn left ahead',
           'Ahead only', 'Go straight or right', 'Go straight or left', 'Keep right',
           'Keep left', 'Roundabout mandatory', 'End of no passing',
           'End of no passing by vehicles over 3.5 metric tons']

# For demonstration purposes, we'll use a cascade classifier for initial detection
# In a real application, you would use the pre-trained model mentioned above
HAAR_CASCADE_PATH = 'haarcascade_frontalface.xml'  # Just for demonstration, would be a traffic sign cascade

def preprocess_image(image, target_size=(32, 32)):
    """Preprocess the image for the model"""
    # Convert to RGB if needed
    if len(image.shape) == 2:
        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
    elif image.shape[2] == 4:
        image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)
    else:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Resize to target size
    image = cv2.resize(image, target_size)

    # Normalize pixel values
    image = image.astype("float32") / 255.0

    return image

def main():
    """Main function to run the traffic sign detection"""
    print("Starting Traffic Sign Detection...")

    # Check if cascade file exists
    try:
        cascade = cv2.CascadeClassifier(HAAR_CASCADE_PATH)
        if cascade.empty():
            raise Exception(f"Error: Could not load cascade classifier from {HAAR_CASCADE_PATH}")
    except Exception as e:
        print(f"Cascade classifier error: {e}")
        print("For demo purposes, we'll continue with basic color detection")
        cascade = None

    # Try to load the model (for demonstration - in a real scenario, you would need a trained model)
    try:
        model = load_model(TRAFFIC_SIGN_MODEL_PATH)
        print(f"Model loaded successfully from {TRAFFIC_SIGN_MODEL_PATH}")
        model_loaded = True
    except Exception as e:
        print(f"Model loading error: {e}")
        print("Running in detection-only mode without classification")
        model_loaded = False

    # Initialize webcam
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("Error: Could not open webcam")
        return

    print("Webcam opened successfully")
    print("Press 'q' to quit")

    while True:
        # Capture frame-by-frame
        ret, frame = cap.read()
        if not ret:
            print("Error: Failed to capture frame")
            break

        # Create a copy of the frame for drawing
        output_frame = frame.copy()

        # Convert to grayscale for detection
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Detect traffic signs
        # In a real application, this would be more sophisticated
        if cascade is not None:
            # Using cascade classifier for demonstration
            detected_objects = cascade.detectMultiScale(
                gray,
                scaleFactor=1.1,
                minNeighbors=5,
                minSize=(30, 30)
            )
        else:
            # Fallback to color-based detection for red traffic signs
            # This is very simplistic and just for demonstration
            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

            # Define range for red color detection (in HSV)
            lower_red1 = np.array([0, 100, 100])
            upper_red1 = np.array([10, 255, 255])
            lower_red2 = np.array([160, 100, 100])
            upper_red2 = np.array([180, 255, 255])

            # Create masks for red color
            mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
            mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
            mask = cv2.bitwise_or(mask1, mask2)

            # Find contours in the mask
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            # Convert to format compatible with the rest of the code
            detected_objects = []
            for contour in contours:
                if cv2.contourArea(contour) > 500:  # Filter by area
                    x, y, w, h = cv2.boundingRect(contour)
                    detected_objects.append((x, y, w, h))

        # Process detected objects
        for (x, y, w, h) in detected_objects:
            # Extract the region of interest
            roi = frame[y:y+h, x:x+w]

            # Check if ROI is not empty
            if roi.size == 0:
                continue

            # Classify the traffic sign if model is loaded
            label = None
            confidence = 0

            if model_loaded:
                try:
                    # Preprocess the ROI
                    processed_roi = preprocess_image(roi)
                    processed_roi = np.expand_dims(processed_roi, axis=0)

                    # Predict using the model
                    predictions = model.predict(processed_roi)
                    class_idx = np.argmax(predictions[0])
                    confidence = predictions[0][class_idx]

                    # Get the class label
                    label = CLASSES[class_idx]
                except Exception as e:
                    print(f"Prediction error: {e}")

            # Draw bounding box
            cv2.rectangle(output_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)

            # Display label and confidence if available
            if label is not None:
                text = f"{label}: {confidence:.2f}"
                cv2.putText(output_frame, text, (x, y-10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            else:
                cv2.putText(output_frame, "Traffic Sign", (x, y-10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # Display FPS
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        cv2.putText(output_frame, f"FPS: {fps}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        # Display the resulting frame
        cv2.imshow('Traffic Sign Detection', output_frame)

        # Break the loop if 'q' is pressed
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # Release the capture and close windows
    cap.release()
    cv2.destroyAllWindows()
    print("Traffic Sign Detection stopped")

if __name__ == "__main__":
    main()

"""
Traffic Sign Detection using OpenCV
This script captures video from a webcam and detects potential traffic signs based on color.
No external model or cascade files are required.
"""

import cv2
import numpy as np
import os
import time

# Define constants for different traffic sign colors
# These HSV ranges can be adjusted for better detection in your environment
RED_SIGNS = [
    {'name': 'Stop/Prohibition', 'lower1': np.array([0, 120, 70]), 'upper1': np.array([10, 255, 255]),
     'lower2': np.array([170, 120, 70]), 'upper2': np.array([180, 255, 255])},
]

BLUE_SIGNS = [
    {'name': 'Information/Mandatory', 'lower': np.array([100, 80, 70]), 'upper': np.array([130, 255, 255])},
]

YELLOW_SIGNS = [
    {'name': 'Warning', 'lower': np.array([20, 100, 100]), 'upper': np.array([35, 255, 255])},
]

# Dummy class list for future implementation
CLASSES = ['Speed limit (20km/h)', 'Speed limit (30km/h)', 'Speed limit (50km/h)',
           'Speed limit (60km/h)', 'Speed limit (70km/h)', 'Speed limit (80km/h)',
           'End of speed limit (80km/h)', 'Speed limit (100km/h)', 'Speed limit (120km/h)',
           'No passing', 'No passing for vehicles over 3.5 metric tons',
           'Right-of-way at the next intersection', 'Priority road', 'Yield', 'Stop',
           'No vehicles', 'Vehicles over 3.5 metric tons prohibited', 'No entry',
           'General caution', 'Dangerous curve to the left', 'Dangerous curve to the right',
           'Double curve', 'Bumpy road', 'Slippery road', 'Road narrows on the right',
           'Road work', 'Traffic signals', 'Pedestrians', 'Children crossing',
           'Bicycles crossing', 'Beware of ice/snow', 'Wild animals crossing',
           'End of all speed and passing limits', 'Turn right ahead', 'Turn left ahead',
           'Ahead only', 'Go straight or right', 'Go straight or left', 'Keep right',
           'Keep left', 'Roundabout mandatory', 'End of no passing',
           'End of no passing by vehicles over 3.5 metric tons']

def detect_by_color(frame):
    """Detect potential traffic signs based on their color"""
    detected_objects = []
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # Detect red signs (requires two ranges in HSV)
    for sign_type in RED_SIGNS:
        mask1 = cv2.inRange(hsv, sign_type['lower1'], sign_type['upper1'])
        mask2 = cv2.inRange(hsv, sign_type['lower2'], sign_type['upper2'])
        mask = cv2.bitwise_or(mask1, mask2)

        # Apply morphological operations to clean up the mask
        kernel = np.ones((5, 5), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

        # Find contours
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for contour in contours:
            if cv2.contourArea(contour) > 400:  # Filter by area
                x, y, w, h = cv2.boundingRect(contour)
                detected_objects.append((x, y, w, h, sign_type['name'], (0, 0, 255)))  # Red color for bbox

    # Detect blue signs
    for sign_type in BLUE_SIGNS:
        mask = cv2.inRange(hsv, sign_type['lower'], sign_type['upper'])
        kernel = np.ones((5, 5), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for contour in contours:
            if cv2.contourArea(contour) > 400:
                x, y, w, h = cv2.boundingRect(contour)
                detected_objects.append((x, y, w, h, sign_type['name'], (255, 0, 0)))  # Blue color for bbox

    # Detect yellow signs
    for sign_type in YELLOW_SIGNS:
        mask = cv2.inRange(hsv, sign_type['lower'], sign_type['upper'])
        kernel = np.ones((5, 5), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for contour in contours:
            if cv2.contourArea(contour) > 400:
                x, y, w, h = cv2.boundingRect(contour)
                detected_objects.append((x, y, w, h, sign_type['name'], (0, 255, 255)))  # Yellow color for bbox

    return detected_objects

def analyze_shape(roi):
    """Basic shape analysis to help identify sign type"""
    # Convert to grayscale and threshold
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)

    # Find contours
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if not contours:
        return "Unknown"

    # Get the largest contour
    cnt = max(contours, key=cv2.contourArea)

    # Approximate the contour to a polygon
    epsilon = 0.04 * cv2.arcLength(cnt, True)
    approx = cv2.approxPolyDP(cnt, epsilon, True)

    # Count the number of vertices
    vertices = len(approx)

    # Analyze shape based on vertices
    if vertices == 3:
        return "Triangle (Warning)"
    elif vertices == 4:
        # Check if it's a square or rectangle
        x, y, w, h = cv2.boundingRect(approx)
        aspect_ratio = float(w) / h
        if 0.9 <= aspect_ratio <= 1.1:
            return "Square (Information)"
        else:
            return "Rectangle (Regulatory)"
    elif vertices == 8:
        return "Octagon (Stop)"
    elif vertices > 8:
        return "Circle (Prohibition/Mandatory)"
    else:
        return "Unknown"

def main():
    """Main function to run the traffic sign detection"""
    print("Starting Traffic Sign Detection...")

    # Try different camera indices if the default doesn't work
    for camera_index in range(3):  # Try camera 0, 1, and 2
        print(f"Trying camera index {camera_index}...")
        cap = cv2.VideoCapture(camera_index)
        if cap.isOpened():
            print(f"Successfully opened camera with index {camera_index}")
            break
        cap.release()

    if not cap.isOpened():
        print("Could not open any camera. Please check your webcam connection.")
        return

    print("Webcam opened successfully")
    print("Press 'q' to quit")

    # Set camera resolution for better performance (if supported)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    # Create named window
    cv2.namedWindow('Traffic Sign Detection', cv2.WINDOW_NORMAL)

    frame_count = 0
    start_time = time.time()
    fps = 0

    while True:
        # Capture frame-by-frame
        ret, frame = cap.read()
        if not ret:
            print("Error: Failed to capture frame")
            # Try to reconnect
            cap.release()
            cap = cv2.VideoCapture(0)
            if not cap.isOpened():
                print("Could not reconnect to camera. Exiting.")
                break
            continue

        # Create a copy of the frame for drawing
        output_frame = frame.copy()

        # Calculate FPS
        frame_count += 1
        if frame_count >= 10:  # Update FPS every 10 frames
            end_time = time.time()
            fps = round(frame_count / (end_time - start_time), 1)
            frame_count = 0
            start_time = time.time()

        # Detect traffic signs based on color
        detected_objects = detect_by_color(frame)

        # Process detected objects
        for (x, y, w, h, sign_type, color) in detected_objects:
            # Extract the region of interest
            roi = frame[y:y+h, x:x+w]

            # Check if ROI is not empty
            if roi.size == 0:
                continue

            # Perform shape analysis for better classification
            shape_info = analyze_shape(roi)

            # Draw bounding box with color based on sign type
            cv2.rectangle(output_frame, (x, y), (x+w, y+h), color, 2)

            # Display label with sign type and shape info
            text = f"{sign_type} - {shape_info}"
            # Add black background for better text visibility
            text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
            cv2.rectangle(output_frame, (x, y-text_size[1]-10), (x+text_size[0], y), (0, 0, 0), -1)
            # Add text
            cv2.putText(output_frame, text, (x, y-5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        # Display FPS
        cv2.putText(output_frame, f"FPS: {fps}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

        # Display instructions
        cv2.putText(output_frame, "Press 'q' to quit", (10, output_frame.shape[0] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        # Display the resulting frame
        cv2.imshow('Traffic Sign Detection', output_frame)

        # Break the loop if 'q' is pressed
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # Release the capture and close windows
    cap.release()
    cv2.destroyAllWindows()
    print("Traffic Sign Detection stopped")

if __name__ == "__main__":
    main()

!pip install ipywidgets

"""
Traffic Sign Detection using OpenCV for Google Colab
This script captures video from a webcam in Google Colab and detects potential traffic signs based on color.
"""

import cv2
import numpy as np
import os
import time
from IPython.display import display, Javascript, Image
from google.colab.output import eval_js
from base64 import b64decode
import matplotlib.pyplot as plt
import io

# Define constants for different traffic sign colors
# These HSV ranges can be adjusted for better detection in your environment
RED_SIGNS = [
    {'name': 'Stop/Prohibition', 'lower1': np.array([0, 120, 70]), 'upper1': np.array([10, 255, 255]),
     'lower2': np.array([170, 120, 70]), 'upper2': np.array([180, 255, 255])},
]

BLUE_SIGNS = [
    {'name': 'Information/Mandatory', 'lower': np.array([100, 80, 70]), 'upper': np.array([130, 255, 255])},
]

YELLOW_SIGNS = [
    {'name': 'Warning', 'lower': np.array([20, 100, 100]), 'upper': np.array([35, 255, 255])},
]

def take_photo(filename='photo.jpg', quality=0.8):
    # Convert quality to a string to avoid the timeout error
    quality_str = str(quality)
    js = Javascript('''
        async function takePhoto(quality) {
            const div = document.createElement('div');
            const capture = document.createElement('button');
            const stopButton = document.createElement('button');
            const video = document.createElement('video');
            const canvas = document.createElement('canvas');

            capture.textContent = 'Capture';
            stopButton.textContent = 'Stop Camera';
            div.appendChild(video);
            div.appendChild(capture);
            div.appendChild(stopButton);

            document.body.appendChild(div);

            video.style.display = 'block';
            const stream = await navigator.mediaDevices.getUserMedia({video: true});

            video.srcObject = stream;
            await video.play();

            // Resize the canvas to match the video feed
            const videoWidth = video.videoWidth;
            const videoHeight = video.videoHeight;
            canvas.width = videoWidth;
            canvas.height = videoHeight;

            let captureInterval = null;
            let captureFlag = false;
            let canvasShown = false;

            capture.onclick = function() {
                if (!captureFlag) {
                    captureFlag = true;
                    capture.textContent = 'Stop Capturing';
                    // Start continuous capture
                    captureInterval = setInterval(() => {
                        const context = canvas.getContext('2d');
                        context.drawImage(video, 0, 0, videoWidth, videoHeight);
                        if (!canvasShown) {
                            div.appendChild(canvas);
                            canvasShown = true;
                        }
                        canvas.toBlob(function(blob) {
                            if (blob) {
                                const reader = new FileReader();
                                reader.onload = function(e) {
                                    const base64data = e.target.result;
                                    google.colab.kernel.invokeFunction('notebook.run', [base64data], {});
                                };
                                reader.readAsDataURL(blob);
                            }
                        }, 'image/jpeg', quality);
                    }, 100); // Capture interval in ms
                } else {
                    captureFlag = false;
                    capture.textContent = 'Capture';
                    clearInterval(captureInterval);
                }
            };

            stopButton.onclick = function() {
                clearInterval(captureInterval);
                video.pause();
                stream.getTracks().forEach(track => {
                    track.stop();
                });
                div.remove();
            };
        }

        takePhoto(''' + quality_str + '''); // Pass quality as a string
    ''')
    display(js)

def js_to_image(js_reply):
    """Convert JS response to OpenCV image"""
    if not js_reply:
        return None

    # Remove the data URL prefix and decode
    b64_data = js_reply.split(',')[1]
    binary = b64decode(b64_data)

    # Convert to numpy array
    image = np.asarray(bytearray(binary), dtype=np.uint8)
    image = cv2.imdecode(image, cv2.IMREAD_COLOR)

    return image

def detect_by_color(frame):
    """Detect potential traffic signs based on their color"""
    detected_objects = []
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # Detect red signs (requires two ranges in HSV)
    for sign_type in RED_SIGNS:
        mask1 = cv2.inRange(hsv, sign_type['lower1'], sign_type['upper1'])
        mask2 = cv2.inRange(hsv, sign_type['lower2'], sign_type['upper2'])
        mask = cv2.bitwise_or(mask1, mask2)

        # Apply morphological operations to clean up the mask
        kernel = np.ones((5, 5), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

        # Find contours
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for contour in contours:
            if cv2.contourArea(contour) > 400:  # Filter by area
                x, y, w, h = cv2.boundingRect(contour)
                detected_objects.append((x, y, w, h, sign_type['name'], (0, 0, 255)))  # Red color for bbox

    # Detect blue signs
    for sign_type in BLUE_SIGNS:
        mask = cv2.inRange(hsv, sign_type['lower'], sign_type['upper'])
        kernel = np.ones((5, 5), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for contour in contours:
            if cv2.contourArea(contour) > 400:
                x, y, w, h = cv2.boundingRect(contour)
                detected_objects.append((x, y, w, h, sign_type['name'], (255, 0, 0)))  # Blue color for bbox

    # Detect yellow signs
    for sign_type in YELLOW_SIGNS:
        mask = cv2.inRange(hsv, sign_type['lower'], sign_type['upper'])
        kernel = np.ones((5, 5), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for contour in contours:
            if cv2.contourArea(contour) > 400:
                x, y, w, h = cv2.boundingRect(contour)
                detected_objects.append((x, y, w, h, sign_type['name'], (0, 255, 255)))  # Yellow color for bbox

    return detected_objects

def analyze_shape(roi):
    """Basic shape analysis to help identify sign type"""
    # Convert to grayscale and threshold
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)

    # Find contours
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if not contours:
        return "Unknown"

    # Get the largest contour
    cnt = max(contours, key=cv2.contourArea)

    # Approximate the contour to a polygon
    epsilon = 0.04 * cv2.arcLength(cnt, True)
    approx = cv2.approxPolyDP(cnt, epsilon, True)

    # Count the number of vertices
    vertices = len(approx)

    # Analyze shape based on vertices
    if vertices == 3:
        return "Triangle (Warning)"
    elif vertices == 4:
        # Check if it's a square or rectangle
        x, y, w, h = cv2.boundingRect(approx)
        aspect_ratio = float(w) / h
        if 0.9 <= aspect_ratio <= 1.1:
            return "Square (Information)"
        else:
            return "Rectangle (Regulatory)"
    elif vertices == 8:
        return "Octagon (Stop)"
    elif vertices > 8:
        return "Circle (Prohibition/Mandatory)"
    else:
        return "Unknown"

def process_and_display(frame):
    """Process the frame and detect traffic signs"""
    if frame is None:
        return

    # Create a copy of the frame for drawing
    output_frame = frame.copy()

    # Detect traffic signs based on color
    detected_objects = detect_by_color(frame)

    # Process detected objects
    for (x, y, w, h, sign_type, color) in detected_objects:
        # Extract the region of interest
        roi = frame[y:y+h, x:x+w]

        # Check if ROI is not empty
        if roi.size == 0:
            continue

        # Perform shape analysis for better classification
        shape_info = analyze_shape(roi)

        # Draw bounding box with color based on sign type
        cv2.rectangle(output_frame, (x, y), (x+w, y+h), color, 2)

        # Display label with sign type and shape info
        text = f"{sign_type} - {shape_info}"
        # Add black background for better text visibility
        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
        cv2.rectangle(output_frame, (x, y-text_size[1]-10), (x+text_size[0], y), (0, 0, 0), -1)
        # Add text
        cv2.putText(output_frame, text, (x, y-5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

    # Convert BGR to RGB for matplotlib
    rgb_image = cv2.cvtColor(output_frame, cv2.COLOR_BGR2RGB)

    # Display with matplotlib
    plt.figure(figsize=(10, 8))
    plt.imshow(rgb_image)
    plt.axis('off')
    plt.show()

    return detected_objects

# Register function to be called from JavaScript
from google.colab import output
output.register_callback('notebook.run', process_and_display)

def main():
    """Main function to run the traffic sign detection"""
    print("Starting Traffic Sign Detection in Google Colab...")
    print("Click 'Capture' to start the webcam feed")
    print("The detected traffic signs will be displayed below each frame")
    take_photo()

if __name__ == "__main__":
    main()